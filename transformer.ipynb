{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600821553314",
   "display_name": "Python 3.7.6 64-bit ('Conda_all': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math as m\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import TransformerEncoder\n",
    "from torch.nn import TransformerDecoder\n",
    "from torch.nn import MultiheadAttention\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from tempfile import NamedTemporaryFile\n",
    "from shutil import unpack_archive\n",
    "zipurl = 'https://download.pytorch.org/tutorial/data.zip'\n",
    "import zipfile, urllib.request, shutil\n",
    "\n",
    "file_name = 'myzip.zip'\n",
    "\n",
    "with urllib.request.urlopen(zipurl) as response, open(file_name, 'wb') as out_file:\n",
    "    shutil.copyfileobj(response, out_file)\n",
    "    with zipfile.ZipFile(file_name) as zf:\n",
    "        zf.extractall()\n",
    "\n",
    "x, y = [], []\n",
    "with open('data//eng-fra.txt', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        tmp = l.rstrip().split('\\t')\n",
    "        x.append(tmp[0].lower())\n",
    "        y.append(tmp[1].lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bpemb import BPEmb\n",
    "bpemb_en = BPEmb(vs = 5000, lang = \"en\")\n",
    "bpemb_fr = BPEmb(vs = 5000, lang = \"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bos_idx = 1\n",
    "eos_idx = 2\n",
    "\n",
    "from bpemb import BPEmb\n",
    "bpemb_en = BPEmb(lang=\"en\", vs=25000)\n",
    "bpemb_fr = BPEmb(lang='fr', vs=25000)\n",
    "\n",
    "\n",
    "max_length = 0\n",
    "\n",
    "\n",
    "xx, yy = [], []\n",
    "#BOS AND EOS HAVE INDEXES 1 AND 2 IN BPE    \n",
    "\n",
    "for i in range(len(x)):\n",
    "    xx_ = [bos_idx]\n",
    "    yy_ = [bos_idx]\n",
    "    \n",
    "    sent1 = xx_\n",
    "    sent2 = yy_\n",
    "    \n",
    "    tmp = bpemb_en.encode_ids(x[i])\n",
    "    sent1.extend(tmp)\n",
    "    \n",
    "    tmp = bpemb_fr.encode_ids(y[i])\n",
    "    sent2.extend(tmp)\n",
    "\n",
    "    xx.append(sent1)\n",
    "    yy.append(sent2)\n",
    "\n",
    "    if len(sent1) > max_length:\n",
    "        max_length = len(sent1)\n",
    "    if len(sent2) > max_length:\n",
    "        max_length = len(sent2)\n",
    "\n",
    "max_length += 2\n",
    "print(xx[3])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000, dropout = 0):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term1 = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        div_term2 = torch.exp(torch.arange(1, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term1)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term2)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class TransformerEnc(nn.Module):\n",
    "    def __init__(self, d_model, dict_size, nhead, batch = 1, dim_feedforward=512, dropout=0, activation='relu', num_layers=6):\n",
    "        super(TransformerEnc, self).__init__()\n",
    "        self.posEnc = PositionalEncoding(d_model, max_length, dropout = dropout)\n",
    "        self.embedding_enc = nn.Embedding.from_pretrained(torch.tensor(bpemb_en.vectors))        \n",
    "        self.enc_layer = nn.TransformerEncoderLayer(d_model, nhead)\n",
    "        self.enc = nn.TransformerEncoder(self.enc_layer, num_layers = num_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.LongTensor(x).to(device)\n",
    "        x = self.embedding_enc(x)\n",
    "        x = self.posEnc(x).transpose(0, 1)\n",
    "        encoder_out = self.enc(x)\n",
    "\n",
    "        \n",
    "        return encoder_out    \n",
    "        \n",
    "        \n",
    "        \n",
    "class TransformerDec(nn.Module):\n",
    "    def __init__(self, d_model, dict_size, max_length, nhead, batch = 1, dim_feedforward=512, dropout=0, activation='relu', num_layers=6):\n",
    "        super(TransformerDec, self).__init__()\n",
    "        self.dec_layer = nn.TransformerDecoderLayer(d_model, nhead, dropout = dropout)\n",
    "        self.posDec = PositionalEncoding(d_model, max_length)\n",
    "        self.embedding_dec = nn.Embedding.from_pretrained(torch.tensor(bpemb_fr.vectors))\n",
    "        self.dec = nn.TransformerDecoder(self.dec_layer, num_layers = num_layers)\n",
    "        self.linear = nn.Linear(d_model, dict_size)        \n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "\n",
    "    def forward(self, x, y=None, mode='eval'):\n",
    "        bs = x.shape[1]\n",
    "        dec_out = None\n",
    "        if(mode == 'train'):\n",
    "           \n",
    "            y = torch.LongTensor(y).to(device)\n",
    "            y = self.embedding_dec(y)\n",
    "            y = self.posDec(y).transpose(0, 1)\n",
    "            pred_dec = self.dec(y, x)\n",
    "            pred_proba_t = self.linear(pred_dec)\n",
    "            dec_out = pred_proba_t.permute(1, 2, 0)\n",
    "        \n",
    "        return dec_out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x, y, max_length, batch = 1):\n",
    "    x_, y_, w_, target_t_ = [], [], [], []\n",
    "    maxk = 0\n",
    "    for i in range(batch):\n",
    "\n",
    "\n",
    "        j = np.random.randint(0, len(x))\n",
    "        \n",
    "\n",
    "        k = np.random.randint(len(y[j]))\n",
    "        if k > maxk:\n",
    "            maxk = k\n",
    "        tmp = torch.zeros(max_length).long()\n",
    "        \n",
    "        tmp[:len(x[j])] = torch.from_numpy(np.array(x[j][:len(x[j])])).long()\n",
    "        tmp[len(x[j])] = eos_idx\n",
    "        x_.append(tmp)\n",
    "\n",
    "        tmp = torch.zeros(max_length).long()\n",
    "        tmp[:len(y[j])]= torch.from_numpy(np.array(y[j][:len(y[j])])).long()\n",
    "        tmp[k+1:] = 0\n",
    "        y_.append(tmp)\n",
    "\n",
    "        tmp = torch.zeros(max_length).long()\n",
    "        tmp[:len(y[j])-1] = torch.from_numpy(np.array(y[j][1:len(y[j])])).long()\n",
    "        tmp[len(y[j])-1] = eos_idx\n",
    "        tmp[:k] = 0\n",
    "        tmp[k+1:] = 0\n",
    "        target_t_.append(tmp)\n",
    "\n",
    "    x_ = torch.cat(x_).reshape(batch, -1)\n",
    "    y_ = torch.cat(y_).reshape(batch, -1)\n",
    "    target_t_ = torch.cat(target_t_).reshape(batch, -1)\n",
    "    w_ = target_t_.clone()\n",
    "    w_[w_ > 0] = 1\n",
    "\n",
    "    return x_, y_[:, :maxk + 1], w_[:, :maxk + 1], target_t_[:, :maxk + 1]\n",
    "\n",
    "\n",
    "def train(input1, target, encoder, decoder, criterion, encoder_optimizer, decoder_optimizer, max_length, num_iters, batch_size):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    for i in range(num_iters):\n",
    "        loss = 0.0\n",
    "        \n",
    "        enc_inp, dec_inp, w, target_t = get_batch(input1, target, max_length, batch = batch_size)\n",
    "\n",
    "        enc_out = encoder.forward(enc_inp)\n",
    "        \n",
    "        dec_out = decoder.forward(enc_out, dec_inp, mode = 'train')\n",
    "\n",
    "        loss = criterion(dec_out, target_t.long().to(device))*w.to(device)\n",
    "\n",
    "        loss = loss.sum()/batch_size\n",
    "        #loss = loss.sum()/(batch_size*w.sum())\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        epoch_loss += loss        \n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "    return epoch_loss/num_iters\n",
    "\n",
    "def getPair(i, data):\n",
    "\n",
    "    return data[0][i], data[1][i]\n",
    "\n",
    "\n",
    "def trainEpochs(encoder, decoder, num_iters, epochs, learning_rate, max_length, data_x, data_y, batch_size, print_in, multiplier, mstep, scale = 1):\n",
    "    start = time.time()\n",
    "\n",
    "    #encoder_optimizer = optim.SGD(encoder.parameters(), lr = learning_rate)\n",
    "    #decoder_optimizer = optim.SGD(decoder.parameters(), lr = learning_rate)\n",
    "    #encoder_optimizer = optim.RMSprop(encoder.parameters(), lr = learning_rate)\n",
    "    #decoder_optimizer = optim.RMSprop(decoder.parameters(), lr = learning_rate)\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr = learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr = learning_rate)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(reduction = 'none')\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    loss = 0\n",
    "    scheduler1 = torch.optim.lr_scheduler.StepLR(encoder_optimizer, step_size=mstep, gamma=multiplier)\n",
    "    scheduler2 = torch.optim.lr_scheduler.StepLR(decoder_optimizer, step_size=mstep, gamma=multiplier)\n",
    "    \n",
    "    \n",
    "    epchs, loss_epochs = [], []\n",
    "\n",
    "\n",
    "    for e in range(epochs):\n",
    "        loss = 0\n",
    "        scheduler1.step()\n",
    "        scheduler2.step()\n",
    "        \n",
    "        loss += train(xx, yy, encoder, decoder, criterion, encoder_optimizer, decoder_optimizer, max_length, num_iters, batch_size)\n",
    "\n",
    "        \n",
    "        if e % print_in == 0:\n",
    "            if e % 30 == 0:\n",
    "                torch.save(encoder1.state_dict(), 'data//encoder.sd')\n",
    "                torch.save(decoder1.state_dict(), 'data//decoder.sd')\n",
    "            epchs.append(e)\n",
    "            loss_epochs.append(loss.item())\n",
    "            print('Epoch: ', e, 'Loss: ', scale*loss, ' Time from Start: ', time.time() - start)\n",
    "\n",
    "\n",
    "    history = pd.DataFrame.from_dict({'epochs': epchs, 'Loss': loss_epochs})\n",
    "    return(history)\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "heads = 10\n",
    "nlayers = 3\n",
    "encoder1 = TransformerEnc(bpemb_en.vectors.shape[1], bpemb_en.vectors.shape[0], heads, num_layers = nlayers).to(device)\n",
    "decoder1 = TransformerDec(bpemb_fr.vectors.shape[1], bpemb_fr.vectors.shape[0], max_length, heads, num_layers = nlayers).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1.load_state_dict(torch.load('data//encoder1.sd'))\n",
    "decoder1.load_state_dict(torch.load('data//decoder1.sd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gamma = 1.1\n",
    "gstep = 10\n",
    "batch_size = 80\n",
    "steps = 1000\n",
    "printevery = 1\n",
    "lr = 0.000005\n",
    "d_model = 61\n",
    "epochs = 100\n",
    "teacher = 1\n",
    "scale = 1000\n",
    "history = trainEpochs(encoder1, decoder1, steps, epochs, lr, max_length, xx, yy, batch_size, printevery, gamma, gstep, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder1.state_dict(), 'data//encoder1.sd')\n",
    "torch.save(decoder1.state_dict(), 'data//decoder1.sd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = 'Spare me the grisly details.'#Spare me the grisly details.\tÉpargnez-moi les détails macabres !\n",
    "def translate(s):\n",
    "    ids = bpemb_en.encode_ids_with_bos_eos(s)\n",
    "    ids = torch.from_numpy(np.array(ids)).long().reshape(1, len(ids))\n",
    "    \n",
    "    encoder1.eval()\n",
    "    decoder1.eval()\n",
    "    o1 = encoder1(ids)\n",
    "    l = [1]\n",
    "    t = 0\n",
    "    for t in range(max_length):\n",
    "        l_ = torch.from_numpy(np.array(l)).reshape(1, len(l)).long()\n",
    "        o2 = decoder1(o1, l_, mode = 'train').argmax(dim = 1)\n",
    "        l.append(o2[0, t].data.tolist())\n",
    "        if(o2[0, t].data.tolist() == 2):\n",
    "            break\n",
    "\n",
    "    return bpemb_fr.decode_ids(l)\n",
    "\n",
    "print(translate(s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}